{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name: Giridhari Lal Gupta\n",
    "##### Roll Number : 2018201019\n",
    "### Naive Baye's Theorem\n",
    "##### Data set downloaded from : http://preon.iiit.ac.in/~sanjoy_chowdhury/LoanDataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import-Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import operator \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "    \n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateByClass(dataset, catAtt, target):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset.iloc[[i]]\n",
    "        if (vector[target].values[0] not in separated):\n",
    "            separated[vector[target].values[0]] = []\n",
    "        separated[vector[target].values[0]].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeByClass(dataset, catAtt, target):\n",
    "    separated = separateByClass(dataset, catAtt, target)\n",
    "    summaries = {}\n",
    "    catSummaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue], catSummaries[classValue] = summarize(instances, catAtt, target)\n",
    "    return summaries, catSummaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(dataset, catAtt, target):\n",
    "    TotalLen = len(dataset)\n",
    "    data = {}\n",
    "    attributes = dataset[0].columns\n",
    "    summaries = {}\n",
    "    catSummaries = {}\n",
    "    for i in attributes:\n",
    "        if i not in catAtt:\n",
    "            summaries[i] = [(0, 0)]\n",
    "        else:\n",
    "            catSummaries[i] = []\n",
    "    for attribute in dataset:\n",
    "        for index in attribute:\n",
    "            if index not in data:\n",
    "                data[index] = []\n",
    "            data[index].append(attribute[index].values[0])\n",
    "    for attribute in data:\n",
    "        if attribute in catAtt:\n",
    "            keyCount = Counter(data[attribute]).keys()\n",
    "            valueCount = Counter(data[attribute]).values()\n",
    "            for key, value in zip_longest(keyCount, valueCount):\n",
    "                catSummaries[attribute].append([(key, value/TotalLen)])\n",
    "        else:\n",
    "            summaries[attribute] = [(mean(data[attribute]), stdev(data[attribute]))]\n",
    "    del summaries[target]\n",
    "    return summaries, catSummaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(summaries, catSummaries, test, catAtt):\n",
    "    prediction = []\n",
    "    for index in range(len(test)):\n",
    "        prediction.append((test.iloc[[index]],getPredict(summaries, catSummaries, test.iloc[[index]], catAtt)))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredict(summaries, catSummaries, testData, catAtt):\n",
    "    probabilities = calculateClassProbabilities(summaries, catSummaries, testData, catAtt)\n",
    "    bestProb, bestLable = -1, None\n",
    "    for label, probability in probabilities.items():\n",
    "        if bestProb < probability:\n",
    "            bestLabel = label\n",
    "            bestProb = probability\n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, catSummaries, testData, catAtt):\n",
    "    probabilities = {}\n",
    "    localProbability = [1, 1]\n",
    "    for label, data in summaries.items():\n",
    "        probabilities[label] = 1\n",
    "        for index, values in data.items():\n",
    "            mean, stdev = values[0]\n",
    "            val = testData[index]\n",
    "            probabilities[label] *= calculateProbaliliy(val, mean, stdev)\n",
    "    for label, data in catSummaries.items():\n",
    "        localProb = 1\n",
    "        for index, values in data.items():\n",
    "            for val in values:\n",
    "#                 print(val[0][0], testData[index].values[0])\n",
    "                if val[0][0] == testData[index].values[0]:\n",
    "                    localProb *= val[0][1]\n",
    "                    break\n",
    "        localProb *= len(data)/4498\n",
    "        localProbability[label] *= localProb\n",
    "    for x in range(2):\n",
    "        probabilities[label] *= localProbability[label]/(localProbability[0] + localProbability[1])   \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbaliliy(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateAccuracy(prediction, target):\n",
    "    correct = 0\n",
    "    for data in prediction:\n",
    "        if str(data[-2][target].values[0]) == str(data[1]):\n",
    "            correct += 1\n",
    "    return correct/len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"../input_data/Q2/LoanDataset/data.csv\", header = None)\n",
    "    df = df.drop([0], axis = 1)\n",
    "    target = 9\n",
    "    train, test = train_test_split(df, test_size = 0.2)\n",
    "    train = train.reset_index()\n",
    "    train = train.drop(['index'], axis = 1)\n",
    "    catAtt = [4, 7, 10, 11, 12, 13]\n",
    "    uniqueValues = np.unique(train[target])\n",
    "    summaries, catSummaries = summarizeByClass(train, catAtt, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictData = prediction(summaries, catSummaries, test, catAtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8855555555555555"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvaluateAccuracy(predictData, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
