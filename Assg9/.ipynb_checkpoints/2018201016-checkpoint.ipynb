{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Danish Mukhtar\n",
    "## Roll NO: 2018201016\n",
    "## Assignment Number : 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEq7gbDtLiDV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pprint import pprint\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df  = pd.read_csv('/home/danish/Music/intrusion_detection/data.csv')\n",
    "eps = np.finfo(float).eps\n",
    "train_data = df\n",
    "Y = train_data['xAttack']\n",
    "X = train_data.iloc[:, :-1]\n",
    "X = (X - X.mean())/X.std()\n",
    "Tr = X.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBcOQZxNLiCk"
   },
   "outputs": [],
   "source": [
    "def sigmoid(gamma):\n",
    "    if gamma < 0:\n",
    "        return 1 - 1/(1 + math.exp(gamma))\n",
    "    else:\n",
    "        return 1/(1 + math.exp(-gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivative for Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBnKaQDyLiCt"
   },
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    return x*(1- x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu and Derivative for Rulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7PGSwuELiC2"
   },
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(0.0, x)\n",
    "\n",
    "def ReLU_derivation(x):\n",
    "    x=x<0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-FXsstQkrBn"
   },
   "outputs": [],
   "source": [
    "def softmax(self, z):\n",
    "        z = z - z.max(axis=0, keepdims=True)\n",
    "        y = np.exp(z)\n",
    "        y = np.nan_to_num(y)\n",
    "        y = y / y.sum(axis=0, keepdims=True)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tanh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUKeuspNLiC8"
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tanh derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zI_w6ehvLiDD"
   },
   "outputs": [],
   "source": [
    "def tanh_derivation(x):\n",
    "    return 1-x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    return x\n",
    "def linear_der(x):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afdK-0S2LiDM"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,nodes_list,learnign_rate,activation_function,activation_prime):\n",
    "        self.nodes=nodes_list\n",
    "        self.layers=len(nodes_list)\n",
    "        self.weights=[]\n",
    "        self.biases=[]\n",
    "        self.debug=False\n",
    "        self.learning_rate=learnign_rate\n",
    "        self.act_func=activation_function\n",
    "        self.act_func_prime = activation_prime\n",
    "        self.epsilon = 1e-15\n",
    "        for i in range(len(nodes_list)-1):\n",
    "            weight_matrix = np.random.randn(nodes_list[i+1],nodes_list[i])*np.sqrt(2/nodes_list[i])\n",
    "            bias_matrix = np.zeros((nodes_list[i+1],1))\n",
    "            self.weights.append(weight_matrix)\n",
    "            self.biases.append(bias_matrix)\n",
    "            \n",
    "    def compute_cost(self, prediction, target):\n",
    "        m = prediction.shape[1]\n",
    "        clipped = np.clip(prediction, self.epsilon, 1 - self.epsilon)\n",
    "        cost = target * np.log(clipped) + (1 - target) * np.log(1 - clipped)\n",
    "        return -np.sum(cost)/m\n",
    "      \n",
    "    def softmax(self, z):\n",
    "        z = z - z.max(axis=0, keepdims=True)\n",
    "        y = np.exp(z)\n",
    "        y = np.nan_to_num(y)\n",
    "        y = y / y.sum(axis=0, keepdims=True)\n",
    "        return y\n",
    "    def show(self):\n",
    "        print(\"Weights\")\n",
    "        print()\n",
    "        for i in range(len(self.weights)):\n",
    "            print(\"Between \",i,\" and \",i+1)\n",
    "            print(self.weights[i].shape)\n",
    "            print(\"\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"Biases \")\n",
    "        print()\n",
    "        for i in range(len(self.weights)):\n",
    "            print(\"Between \",i,\" and \",i+1)\n",
    "            print(self.biases[i].shape)\n",
    "            print(\"\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"Number of Layers : \",self.layers)\n",
    "        print(\"Nodes Per Layer : \",self.nodes)\n",
    "        print(\"Learning Rate : \",self.learning_rate)\n",
    "        print(\"Activation Function: \",self.act_func)\n",
    "        print(\"Activation derivative : \",self.act_func_prime)\n",
    "        \n",
    "    def feed_forward(self,input_array, length):\n",
    "        X = np.array(input_array).T\n",
    "        for i in range(len(self.weights)-1):\n",
    "            print(i)\n",
    "            X=np.dot(self.weights[i],X)\n",
    "            X=X+self.biases[i]\n",
    "            ff = np.vectorize(self.act_func)\n",
    "            X=ff(X)\n",
    "\n",
    "        return X\n",
    "      \n",
    "    def train(self,input_array,target,m):\n",
    "        X = np.array(input_array).T\n",
    "        outputs=[]\n",
    "        inputs=[]\n",
    "        inputs.append(X)\n",
    "        for i in range(len(self.weights)-1):\n",
    "            X=np.dot(self.weights[i],X)\n",
    "            X=X+self.biases[i]\n",
    "            ff = np.vectorize(self.act_func)\n",
    "            X=ff(X)\n",
    "            outputs.append(X)\n",
    "            inputs.append(X)\n",
    "        \n",
    "        \n",
    "        X=np.dot(self.weights[len(self.weights)-1],X)\n",
    "        X=X+self.biases[len(self.weights)-1]\n",
    "        outputs.append(X)\n",
    "        inputs.append(X)\n",
    "        predicted = X\n",
    "        \n",
    "        target = np.array(target).T\n",
    "        errors=[]\n",
    "        \n",
    "        error = target - predicted\n",
    "        errors.append(error)\n",
    "        i = len(self.weights)-1\n",
    "      \n",
    "        while(i>0):\n",
    "            error  = np.dot(self.weights[i].T,error)\n",
    "            i-=1\n",
    "            errors.append(error)\n",
    "        i = len(self.weights)-1\n",
    "        \n",
    "        errors=list(reversed(errors))\n",
    "        act_fun_pr = self.act_func_prime\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        gradients = target-predicted\n",
    "        delta_weight = (1/m)*self.learning_rate* np.dot(gradients,inputs[i].T)\n",
    "\n",
    "        self.weights[i]+=delta_weight\n",
    "        meaner = gradients.mean(axis=1)\n",
    "        self.biases[i]+=self.learning_rate * meaner.reshape(len(meaner),1)\n",
    "        i-=1        \n",
    "        \n",
    "        while(i>=0):\n",
    "            gradients = act_fun_pr(outputs[i])\n",
    "            gradients = (errors[i]*gradients)\n",
    "            gradients = gradients.reshape(len(gradients),len(gradients[0]))\n",
    "            delta_weight = (1/m)*self.learning_rate*np.dot(gradients,inputs[i].T)\n",
    "            \n",
    "            self.weights[i]+=delta_weight\n",
    "            meaner = gradients.mean(axis=1)\n",
    "            self.biases[i]+=self.learning_rate*meaner.reshape(len(meaner),1)\n",
    "            i-=1\n",
    "            \n",
    "        return \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzfahV6xLiEL"
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "nn = NeuralNetwork([29,14,29],0.1,tanh,tanh_derivation)\n",
    "batch=512\n",
    "accuracy_list=[]\n",
    "for epocs in range(10):\n",
    "    for i in range(0,len(Tr)-batch,batch):\n",
    "        nn.train(Tr[i:i+batch],Tr[i:i+batch],batch)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "WREnem4Uu5vq",
    "outputId": "e4ecfa18-8e73-4184-be4f-10a7af3cba49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "newdata = nn.feed_forward(Tr,3)\n",
    "newdata = newdata.T\n",
    "newdata = pd.DataFrame(newdata)\n",
    "newdata.shape\n",
    "X=newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.628736</td>\n",
       "      <td>-0.701327</td>\n",
       "      <td>0.584046</td>\n",
       "      <td>-0.770136</td>\n",
       "      <td>-0.669001</td>\n",
       "      <td>0.416662</td>\n",
       "      <td>-0.610686</td>\n",
       "      <td>-0.545445</td>\n",
       "      <td>0.067607</td>\n",
       "      <td>0.630215</td>\n",
       "      <td>0.756498</td>\n",
       "      <td>-0.163380</td>\n",
       "      <td>-0.516615</td>\n",
       "      <td>-0.709844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.925064</td>\n",
       "      <td>-0.044300</td>\n",
       "      <td>-0.808301</td>\n",
       "      <td>-0.667560</td>\n",
       "      <td>-0.569325</td>\n",
       "      <td>-0.709578</td>\n",
       "      <td>0.441118</td>\n",
       "      <td>0.685934</td>\n",
       "      <td>0.857687</td>\n",
       "      <td>-0.737198</td>\n",
       "      <td>0.612032</td>\n",
       "      <td>-0.374583</td>\n",
       "      <td>0.435345</td>\n",
       "      <td>0.493158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.587200</td>\n",
       "      <td>-0.731697</td>\n",
       "      <td>0.624668</td>\n",
       "      <td>-0.828849</td>\n",
       "      <td>-0.710245</td>\n",
       "      <td>0.503158</td>\n",
       "      <td>-0.611872</td>\n",
       "      <td>-0.443320</td>\n",
       "      <td>0.124948</td>\n",
       "      <td>0.663420</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>-0.298210</td>\n",
       "      <td>-0.593501</td>\n",
       "      <td>-0.639710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.696077</td>\n",
       "      <td>-0.175967</td>\n",
       "      <td>-0.238950</td>\n",
       "      <td>-0.706764</td>\n",
       "      <td>-0.854707</td>\n",
       "      <td>0.275703</td>\n",
       "      <td>0.160286</td>\n",
       "      <td>-0.170836</td>\n",
       "      <td>-0.139086</td>\n",
       "      <td>0.759924</td>\n",
       "      <td>0.650677</td>\n",
       "      <td>-0.036485</td>\n",
       "      <td>-0.457560</td>\n",
       "      <td>0.338752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.893793</td>\n",
       "      <td>-0.837030</td>\n",
       "      <td>-0.834322</td>\n",
       "      <td>0.707431</td>\n",
       "      <td>0.656859</td>\n",
       "      <td>0.729388</td>\n",
       "      <td>0.700179</td>\n",
       "      <td>0.774072</td>\n",
       "      <td>-0.841093</td>\n",
       "      <td>0.608295</td>\n",
       "      <td>-0.861341</td>\n",
       "      <td>-0.874229</td>\n",
       "      <td>0.675424</td>\n",
       "      <td>0.691559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.628736 -0.701327  0.584046 -0.770136 -0.669001  0.416662 -0.610686   \n",
       "1 -0.925064 -0.044300 -0.808301 -0.667560 -0.569325 -0.709578  0.441118   \n",
       "2  0.587200 -0.731697  0.624668 -0.828849 -0.710245  0.503158 -0.611872   \n",
       "3  0.696077 -0.175967 -0.238950 -0.706764 -0.854707  0.275703  0.160286   \n",
       "4 -0.893793 -0.837030 -0.834322  0.707431  0.656859  0.729388  0.700179   \n",
       "\n",
       "         7         8         9         10        11        12        13  \n",
       "0 -0.545445  0.067607  0.630215  0.756498 -0.163380 -0.516615 -0.709844  \n",
       "1  0.685934  0.857687 -0.737198  0.612032 -0.374583  0.435345  0.493158  \n",
       "2 -0.443320  0.124948  0.663420  0.789744 -0.298210 -0.593501 -0.639710  \n",
       "3 -0.170836 -0.139086  0.759924  0.650677 -0.036485 -0.457560  0.338752  \n",
       "4  0.774072 -0.841093  0.608295 -0.861341 -0.874229  0.675424  0.691559  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euclidean_distance(node1,node2):\n",
    "    return np.linalg.norm(node1-node2)\n",
    "def clustering_start_centroids(data,k=5):\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    mat=X.values\n",
    "    y=0\n",
    "    while y!=5:\n",
    "        centroids = {}\n",
    "        for i in range(k):\n",
    "            coord = []\n",
    "            for j in range(len(mat[0])):\n",
    "                coord.append(np.random.randint(int(min(mat[:,j])),int(max(mat[:,j]))))\n",
    "            centroids[i]=coord\n",
    "        finaler=[]\n",
    "        for featureset in data:\n",
    "                distances = [np.linalg.norm(featureset-centroids[centroid]) for centroid in centroids]    \n",
    "                classification = np.argmin(distances)\n",
    "                finaler.append(classification)\n",
    "        finaler_S = set(finaler)\n",
    "        y=len(finaler_S)\n",
    "    return centroids,finaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "start,finaler = clustering_start_centroids(np.array(X),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "k=5\n",
    "data = X.values\n",
    "counter = 10\n",
    "centroids=start\n",
    "c_old=finaler\n",
    "\n",
    "while counter:\n",
    "    classifications ={} \n",
    "    for i in range(k):\n",
    "        classifications[i]=[]\n",
    "    \n",
    "    c_old=copy.deepcopy(finaler)\n",
    "    finaler=[]\n",
    "    for featureset in data:\n",
    "            distances = [np.linalg.norm(featureset-centroids[centroid]) for centroid in centroids]    \n",
    "            classification = np.argmin(distances)\n",
    "            finaler.append(classification)\n",
    "            classifications[classification].append(featureset)\n",
    "    counter-=1\n",
    "    prev_centroids = dict(centroids)\n",
    "    for classification in classifications:\n",
    "        centroids[classification] = np.average(classifications[classification],axis=0)\n",
    "    if counter==0 or c_old==finaler:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average purity is 0.8447875830066406\n"
     ]
    }
   ],
   "source": [
    "train_data = df\n",
    "Y = train_data.iloc[:,29:30]\n",
    "a_label=np.array(Y)\n",
    "final_result=newdata.values\n",
    "data = final_result\n",
    "c_mat = np.zeros((5,5))\n",
    "c_mat = c_mat.astype(int)\n",
    "c_label=finaler\n",
    "cleanup_nums = {\"xAttack\":{\"normal\": 0, \"dos\": 1, \"probe\": 2, \"r2l\" : 3, \"u2r\": 4}}\n",
    "new_df = Y\n",
    "new_df.replace(cleanup_nums, inplace=True)\n",
    "actual_labels = np.array(new_df['xAttack'])\n",
    "for i in range(len(c_label)):\n",
    "    x = c_label[i]\n",
    "    c_mat[x,actual_labels[i]] += 1\n",
    "\n",
    "temp = np.amax(c_mat,axis=1)\n",
    "purity_K = float(np.sum(temp))/len(c_label)\n",
    "print(' Average purity is ' + str(purity_K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7FWUXaSAxGq"
   },
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0GhjIG4hLiEm"
   },
   "outputs": [],
   "source": [
    "data = X\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=5).fit(data)\n",
    "c_label = gmm.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "1E9oD19WrPpp",
    "outputId": "0a058c79-0e91-429d-bb10-4e530e59cd2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Purity is  0.8051444115529243\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data_1 = df\n",
    "Y=train_data_1.iloc[:,29:30]\n",
    "data = final_result\n",
    "c_mat = np.zeros((5,5))\n",
    "c_mat = c_mat.astype(int)\n",
    "\n",
    "cleanup_nums = {\"xAttack\":{\"normal\": 0, \"dos\": 1, \"probe\": 2, \"r2l\" : 3, \"u2r\": 4}}\n",
    "new_df = Y\n",
    "new_df.replace(cleanup_nums, inplace=True)\n",
    "new_df.head()\n",
    "actual_labels = np.array(new_df['xAttack'])\n",
    "for i in range(len(c_label)):\n",
    "    x = c_label[i]\n",
    "    c_mat[x,actual_labels[i]] += 1\n",
    "\n",
    "temp = np.amax(c_mat,axis=1)\n",
    "purity_G = float(np.sum(temp))/len(c_label)\n",
    "print(\"Average Purity is \",purity_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXJWic7CA3Jy"
   },
   "source": [
    "## Hierarical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMRA-ERlsRiY"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "xvLf6QItocMs",
    "outputId": "2ba43297-8c91-4543-ca7a-5359f08e9022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average purity is 0.8049843987519002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Hier(X):\n",
    "    data= X\n",
    "    Hclustering = AgglomerativeClustering(n_clusters=5,affinity='euclidean', linkage='ward')\n",
    "    Hclustering.fit(data)\n",
    "    return Hclustering\n",
    "CLus = Hier(X)\n",
    "c_label=CLus.labels_\n",
    "tem = df\n",
    "Y=tem.iloc[:,29:30]\n",
    "a_label=np.array(Y)\n",
    "data = final_result\n",
    "c_mat = np.zeros((5,5))\n",
    "c_mat = c_mat.astype(int)\n",
    "\n",
    "cleanup_nums = {\"xAttack\":{\"normal\": 0, \"dos\": 1, \"probe\": 2, \"r2l\" : 3, \"u2r\": 4}}\n",
    "new_df = Y\n",
    "new_df.replace(cleanup_nums, inplace=True)\n",
    "new_df.head()\n",
    "actual_labels = np.array(new_df['xAttack'])\n",
    "for i in range(len(c_label)):\n",
    "    x = c_label[i]\n",
    "    c_mat[x,actual_labels[i]] += 1\n",
    "temp = np.amax(c_mat,axis=1)\n",
    "purity_H = float(np.sum(temp))/len(c_label)\n",
    "print('Average purity is ' + str(purity_H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pprint import pprint\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df  = pd.read_csv('/home/danish/Music/intrusion_detection/data.csv')\n",
    "eps = np.finfo(float).eps\n",
    "train_data = df\n",
    "Y = train_data['xAttack']\n",
    "X = train_data.iloc[:, :-1]\n",
    "X = (X - X.mean())/X.std()\n",
    "Tr = X.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "nn = NeuralNetwork([29,14,29],0.01,linear,linear_der)\n",
    "batch=512\n",
    "accuracy_list=[]\n",
    "for epocs in range(10):\n",
    "    for i in range(0,len(Tr)-batch,batch):\n",
    "        nn.train(Tr[i:i+batch],Tr[i:i+batch],batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "newdata = nn.feed_forward(Tr,3)\n",
    "newdata = newdata.T\n",
    "newdata = pd.DataFrame(newdata)\n",
    "newdata.shape\n",
    "X=newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k- MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "start,finaler = clustering_start_centroids(np.array(X),5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "k=5\n",
    "data = X.values\n",
    "counter = 10\n",
    "centroids=start\n",
    "c_old=finaler\n",
    "purity_K=0.27\n",
    "while counter:\n",
    "    classifications ={} \n",
    "    for i in range(k):\n",
    "        classifications[i]=[]\n",
    "    \n",
    "    c_old=copy.deepcopy(finaler)\n",
    "    finaler=[]\n",
    "    for featureset in data:\n",
    "            distances = [np.linalg.norm(featureset-centroids[centroid]) for centroid in centroids]    \n",
    "            classification = np.argmin(distances)\n",
    "            finaler.append(classification)\n",
    "            classifications[classification].append(featureset)\n",
    "    counter-=1\n",
    "    prev_centroids = dict(centroids)\n",
    "    for classification in classifications:\n",
    "        centroids[classification] = np.average(classifications[classification],axis=0)\n",
    "    if counter==0 or c_old==finaler:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average purity is 0.8046427714217138\n"
     ]
    }
   ],
   "source": [
    "train_data = df\n",
    "Y = train_data.iloc[:,29:30]\n",
    "a_label=np.array(Y)\n",
    "final_result=newdata.values\n",
    "data = final_result\n",
    "c_mat = np.zeros((5,5))\n",
    "c_mat = c_mat.astype(int)\n",
    "c_label=finaler\n",
    "cleanup_nums = {\"xAttack\":{\"normal\": 0, \"dos\": 1, \"probe\": 2, \"r2l\" : 3, \"u2r\": 4}}\n",
    "new_df = Y\n",
    "new_df.replace(cleanup_nums, inplace=True)\n",
    "actual_labels = np.array(new_df['xAttack'])\n",
    "for i in range(len(c_label)):\n",
    "    x = c_label[i]\n",
    "    c_mat[x,actual_labels[i]] += 1\n",
    "\n",
    "temp = np.amax(c_mat,axis=1)\n",
    "purity_K+= float(np.sum(temp))/len(c_label)\n",
    "print(' Average purity is ' + str(purity_K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=5).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Purity is  0.785022801824146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danish/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5821: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  regex=regex)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c_label = gmm.predict(data)\n",
    "train_data_1 = df\n",
    "Y=train_data_1.iloc[:,29:30]\n",
    "data = final_result\n",
    "c_mat = np.zeros((5,5))\n",
    "c_mat = c_mat.astype(int)\n",
    "\n",
    "\n",
    "cleanup_nums = {\"xAttack\":{\"normal\": 0, \"dos\": 1, \"probe\": 2, \"r2l\" : 3, \"u2r\": 4}}\n",
    "new_df = Y\n",
    "new_df.replace(cleanup_nums, inplace=True)\n",
    "new_df.head()\n",
    "actual_labels = np.array(new_df['xAttack'])\n",
    "for i in range(len(c_label)):\n",
    "    x = c_label[i]\n",
    "    c_mat[x,actual_labels[i]] += 1\n",
    "\n",
    "temp = np.amax(c_mat,axis=1)\n",
    "purity_G = float(np.sum(temp))/len(c_label)\n",
    "print(\"Average Purity is \",purity_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heirarical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average purity is 0.8336666933354668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danish/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5821: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  regex=regex)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "def Hier(X):\n",
    "    data= X\n",
    "    Hclustering = AgglomerativeClustering(n_clusters=5,affinity='euclidean', linkage='ward')\n",
    "    Hclustering.fit(data)\n",
    "    return Hclustering\n",
    "CLus = Hier(X)\n",
    "c_label=CLus.labels_\n",
    "tem = df\n",
    "Y=tem.iloc[:,29:30]\n",
    "a_label=np.array(Y)\n",
    "data = final_result\n",
    "c_mat = np.zeros((5,5))\n",
    "c_mat = c_mat.astype(int)\n",
    "\n",
    "cleanup_nums = {\"xAttack\":{\"normal\": 0, \"dos\": 1, \"probe\": 2, \"r2l\" : 3, \"u2r\": 4}}\n",
    "new_df = Y\n",
    "new_df.replace(cleanup_nums, inplace=True)\n",
    "new_df.head()\n",
    "actual_labels = np.array(new_df['xAttack'])\n",
    "for i in range(len(c_label)):\n",
    "    x = c_label[i]\n",
    "    c_mat[x,actual_labels[i]] += 1\n",
    "temp = np.amax(c_mat,axis=1)\n",
    "purity_H = float(np.sum(temp))/len(c_label)\n",
    "print('Average purity is ' + str(purity_H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pprint import pprint\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df  = pd.read_csv('/home/danish/Music/intrusion_detection/data.csv')\n",
    "eps = np.finfo(float).eps\n",
    "train_data = df\n",
    "Y = train_data['xAttack']\n",
    "X = train_data.iloc[:, :-1]\n",
    "X = (X - X.mean())/X.std()\n",
    "Tr = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "nn = NeuralNetwork([29,14,14,29],0.4,tanh,tanh_derivation)\n",
    "batch=512\n",
    "accuracy_list=[]\n",
    "for epocs in range(10):\n",
    "    for i in range(0,len(Tr)-batch,batch):\n",
    "        nn.train(Tr[i:i+batch],Tr[i:i+batch],batch)\n",
    "\n",
    "newdata = nn.feed_forward(Tr,3)\n",
    "newdata = newdata.T\n",
    "newdata = pd.DataFrame(newdata)\n",
    "newdata.shape\n",
    "X=newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "start,finaler = clustering_start_centroids(np.array(X),5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "start,finaler = clustering_start_centroids(np.array(X),5)\n",
    "import copy\n",
    "k=5\n",
    "data = X.values\n",
    "counter = 10\n",
    "centroids=start\n",
    "c_old=finaler\n",
    "purity_K=0.27\n",
    "while counter:\n",
    "    classifications ={} \n",
    "    for i in range(k):\n",
    "        classifications[i]=[]\n",
    "    \n",
    "    c_old=copy.deepcopy(finaler)\n",
    "    finaler=[]\n",
    "    for featureset in data:\n",
    "            distances = [np.linalg.norm(featureset-centroids[centroid]) for centroid in centroids]    \n",
    "            classification = np.argmin(distances)\n",
    "            finaler.append(classification)\n",
    "            classifications[classification].append(featureset)\n",
    "    counter-=1\n",
    "    prev_centroids = dict(centroids)\n",
    "    for classification in classifications:\n",
    "        centroids[classification] = np.average(classifications[classification],axis=0)\n",
    "    if counter==0 or c_old==finaler:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average purity is 0.7755420433634691\n"
     ]
    }
   ],
   "source": [
    "train_data = df\n",
    "Y = train_data.iloc[:,29:30]\n",
    "a_label=np.array(Y)\n",
    "final_result=newdata.values\n",
    "data = final_result\n",
    "c_mat = np.zeros((5,5))\n",
    "c_mat = c_mat.astype(int)\n",
    "c_label=finaler\n",
    "cleanup_nums = {\"xAttack\":{\"normal\": 0, \"dos\": 1, \"probe\": 2, \"r2l\" : 3, \"u2r\": 4}}\n",
    "new_df = Y\n",
    "new_df.replace(cleanup_nums, inplace=True)\n",
    "actual_labels = np.array(new_df['xAttack'])\n",
    "for i in range(len(c_label)):\n",
    "    x = c_label[i]\n",
    "    c_mat[x,actual_labels[i]] += 1\n",
    "\n",
    "temp = np.amax(c_mat,axis=1)\n",
    "purity_K= float(np.sum(temp))/len(c_label)\n",
    "print(' Average purity is ' + str(purity_K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=5).fit(data)\n",
    "c_label = gmm.predict(data)\n",
    "train_data_1 = df\n",
    "Y=train_data_1.iloc[:,29:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Purity is  0.8326666133290663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danish/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5821: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  regex=regex)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = final_result\n",
    "c_mat = np.zeros((5,5))\n",
    "c_mat = c_mat.astype(int)\n",
    "\n",
    "\n",
    "cleanup_nums = {\"xAttack\":{\"normal\": 0, \"dos\": 1, \"probe\": 2, \"r2l\" : 3, \"u2r\": 4}}\n",
    "new_df = Y\n",
    "new_df.replace(cleanup_nums, inplace=True)\n",
    "new_df.head()\n",
    "actual_labels = np.array(new_df['xAttack'])\n",
    "for i in range(len(c_label)):\n",
    "    x = c_label[i]\n",
    "    c_mat[x,actual_labels[i]] += 1\n",
    "\n",
    "temp = np.amax(c_mat,axis=1)\n",
    "purity_G = float(np.sum(temp))/len(c_label)\n",
    "print(\"Average Purity is \",purity_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEIRARICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average purity is 0.8162252980238419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danish/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5821: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  regex=regex)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "def Hier(X):\n",
    "    data= X\n",
    "    Hclustering = AgglomerativeClustering(n_clusters=5,affinity='euclidean', linkage='ward')\n",
    "    Hclustering.fit(data)\n",
    "    return Hclustering\n",
    "CLus = Hier(X)\n",
    "c_label=CLus.labels_\n",
    "tem = df\n",
    "Y=tem.iloc[:,29:30]\n",
    "a_label=np.array(Y)\n",
    "data = final_result\n",
    "c_mat = np.zeros((5,5))\n",
    "c_mat = c_mat.astype(int)\n",
    "\n",
    "cleanup_nums = {\"xAttack\":{\"normal\": 0, \"dos\": 1, \"probe\": 2, \"r2l\" : 3, \"u2r\": 4}}\n",
    "new_df = Y\n",
    "new_df.replace(cleanup_nums, inplace=True)\n",
    "new_df.head()\n",
    "actual_labels = np.array(new_df['xAttack'])\n",
    "for i in range(len(c_label)):\n",
    "    x = c_label[i]\n",
    "    c_mat[x,actual_labels[i]] += 1\n",
    "temp = np.amax(c_mat,axis=1)\n",
    "purity_H = float(np.sum(temp))/len(c_label)\n",
    "print('Average purity is ' + str(purity_H))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
